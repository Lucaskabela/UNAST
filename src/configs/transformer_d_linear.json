{
    "seed": 0,
    "epochs": 300,
    "lr": 2e-3,
    "weight_decay": 1e-6,
    "sched_type": "linear",
    "warmup_steps": 2000,
    "teacher_init_val": 1,
    "teacher_gamma": 0.98,
    "teacher_decay_start": 301,
    "teacher_decay_end": 301,
    "grad_clip": 1.0,
    "train_batch_size": 4,
    "eval_batch_size": 128,
    "epoch_steps": 50,
    "tb_example_step": 5,
    "ae_steps": 4,
    "cm_steps": 8,
    "sp_steps": 4,
    "d_steps": 4,
    "checkpoint_path": "./checkpoint/transformer_d_b4_a4_linear",
    "sample_path": "./samples/transformer_d_b4_a4_linear",
    "tb_log_path": "./log_tb/transformer_d_b4_a4_linear",
    "num_mels": 80,
    "s_pre_hid": 256,
    "s_pre_drop": 0.5,
    "s_post_drop": 0.1,
    "t_emb_dim": 256,
    "t_pre_drop": 0.5,
    "t_post_drop": 0.1,
    "hidden": 256,
    "e_in": 256,
    "e_drop": 0.1,
    "num_layers": 4,
    "nhead": 4,
    "ffn_dim": 1024,
    "d_drop": 0.1,
    "use_discriminator": true,
    "disc_hid": 64,
    "disc_bidirectional": true,
    "disc_num_layers": 2,
    "s_eos_weight": 5.0,
    "t_eos_weight": 1.0,
    "num_workers": 4,
    "load_path": "./checkpoint/transformer_d_b4_a4_linear/model_most_recent.ckpt",
    "save_every": 10,
    "use_gpu": true,
    "optim_type": "adamw",
    "model_type": "transformer"
}
