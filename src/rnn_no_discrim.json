{
    "seed": 0,
    "epochs": 500,
    "lr": 1e-3,
    "weight_decay": 1e-6,
    "sched_type": "multistep",
    "lr_milestones": [
        100,
        150
    ],
    "lr_gamma": 0.1,
    "teacher_init_val": 1,
    "teacher_gamma": 0.98,
    "teacher_decay_start": 501,
    "teacher_decay_end": 501,
    "grad_clip": 1.0,
    "train_batch_size": 8,
    "eval_batch_size": 128,
    "epoch_steps": 50,
    "tb_example_step": 5,
    "ae_steps": 2,
    "cm_steps": 4,
    "sp_steps": 2,
    "d_steps": 2,
    "checkpoint_path": "./checkpoint/rnn_b8_a2_luong",
    "sample_path": "./samples/rnn_b8_a2_luong",
    "tb_log_path": "./log_tb/rnn_b8_a2_luong",
    "num_mels": 80,
    "s_pre_hid": 256,
    "s_pre_drop": 0.5,
    "s_post_drop": 0.1,
    "t_emb_dim": 256,
    "t_pre_drop": 0.5,
    "t_post_drop": 0.1,
    "hidden": 256,
    "e_in": 256,
    "e_drop": 0.5,
    "num_layers": 2,
    "e_bi": true,
    "d_drop": 0.3,
    "d_attn": "luong",
    "attn_dim": 32,
    "s_eos_weight": 5.0,
    "t_eos_weight": 3.0,
    "num_workers": 4,
    "load_path": null,
    "save_every": 10,
    "use_discriminator": false,
    "use_gpu": true,
    "optim_type": "adamw",
    "model_type": "rnn"
}
